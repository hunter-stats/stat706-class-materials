---
title: "Homework 3 - Chapter Question 2"
author: "Nickhil Sethi"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, width.cutoff=50)
library(ggplot2)
library(printr)
library(gridExtra)
library(faraway)
```


Load pima dataset:
```{r}
data("pima")
```
## 2.a
See below for the interleaved histogram plot. One thing that does seem unbelievable about this plot -- is the very large number of zeros on the insulin variable, both for positive and negative tests. This suggests to me either a possible coding error or 0 representing missing data.
```{r}
ggplot(pima, aes(x=insulin, fill=factor(test))) + 
geom_histogram(
  alpha=.6, position="dodge", binwidth=10)
```

## 2.b
Without the incredible zero values, insulin appears to have a poisson distribution with mean conditional on the test outcome:
```{r}
pima$insulin[pima$insulin == 0] <- NA
ggplot(pima, aes(x=insulin, fill=factor(test))) + geom_histogram(position="dodge", binwidth=10)
```

## 2.c
Let's plot the other variables and inspect for any suspect zero values: 
```{r}
g1 <- ggplot(pima, aes(x=glucose, fill=factor(test))) + geom_histogram(position="dodge", binwidth=10)

g2 <- ggplot(pima, aes(x=bmi, fill=factor(test))) + geom_histogram(position="dodge", binwidth=5)

g3 <- ggplot(pima, aes(x=diabetes, fill=factor(test))) + geom_histogram(position="dodge", binwidth=.1)

g4 <- ggplot(pima, aes(x=triceps, fill=factor(test))) + geom_histogram(position="dodge", binwidth=.1)

g5 <- ggplot(pima, aes(x=age, fill=factor(test))) + geom_histogram(position="dodge", binwidth=.1)

g6 <- ggplot(pima, aes(x=pregnant, fill=factor(test))) + geom_histogram(position="dodge", binwidth=.1)

g7 <- ggplot(pima, aes(x=diastolic, fill=factor(test))) + geom_histogram(position="dodge", binwidth=.1)

grid.arrange(g1, g2, g3, g4, g5, g6, g7, ncol=2)
```

It seems the following variables have incredible zeros:
```{r}
pima$glucose[pima$glucose == 0] <- NA
pima$bmi[pima$bmi == 0] <- NA
pima$triceps[pima$triceps == 0] <- NA
pima$diastolic[pima$diastolic == 0] <- NA
nrow(pima)
```
Now let's regress test on the other variables. 392 of the 768 rows in $pima$ were used, with the rest being dropped due a column having a value of `NA`.

```{r}
# number of rows 
# in the pima dataset 
nrow(pima)

# fit the model
lmod <- glm(test ~ ., family=binomial, pima)
sumary(lmod)
```

## 2.d

Running this model without $insulin$ and $triceps$ predictors, we see that 724 observations are now used in the model, indicating most of the $NA$ values 
were in those two columns.
```{r}
lmod2 <- glm(test ~ pregnant + glucose + diastolic 
          + bmi + diabetes + age, family=binomial, pima)
sumary(lmod2)
```

Now to test the significance of the smaller model against the larger model, we look at the difference in the deviances of the two models, which should be chi-squared distributed under null. As we can see below, the deviance of the smaller model is much higher than larger model, indicating a better fit; in fact 
the p-value for this difference is below machine precision, so it prints as 0.
```{r}
diff <- deviance(lmod2) - deviance(lmod)
diff
num_coef_diff <- length(coef(lmod)) - length(coef(lmod2))
p_val <- 1 - pchisq(diff, num_coef_diff)
sprintf("%.10f", p_val)
```


## 2.e
Now let's compare based on AIC, using the $step$ command, starting from the largest possible model $lmod$
```{r}
# required to get step to 
# work without error
pima_omit_na <- na.omit(pima)
lmod <- glm(test ~ pregnant + glucose + diastolic + triceps
          + insulin + bmi + diabetes + age, family=binomial, pima_omit_na)
lmodr <- step(lmod, trace=0)
sumary(lmodr)
```
As we can see, $pregnant$, $bmi$, $diabetes$, and $age$ are selected as predictors (although it's noteworthy that the p-value on $pregnant$ is doesn't pass significance). 392 data points are used in the final model.

## 2.f

```{r}
# let's add a column 
# to the dataframe representing
# if the row has any missing values at all
pima$has_missing <- !complete.cases(pima)

# now let's regress test 
# on has_missing
lmod_missing_values <- glm(
  test ~ as.numeric(has_missing), 
  family=binomial, pima)

sumary(lmod_missing_values)

# plotting this relationship,
# we can see visually there isn't much of a 
# correlation between the two variables
plot(jitter(as.numeric(has_missing), .5) ~ jitter(test, .5), xlab="test", ylab="has missing", pima)

```

As we can see above, the coefficient on $has\_missing$ in the regression is slight and has a p-value of .3, indicating we should not reject the null that $test$ and $has\_missing$ are uncorrelated. 

See above for a jittered plot of $has\_missing$ against $test$. Because $has\_missing$ is uncorrelated with the response, it's fine to drop missing data when we run the following regression.

```{r}
# now let's rerun the previous model on the whole dataset
lmodr2 <- glm(test ~ pregnant + glucose + bmi + diabetes + age, family = binomial, pima)
sumary(lmodr)
sumary(lmodr2)
```

## 2.g

Let's compute the $odds\_ratio$, which captures the "difference" (as a ratio) between the odds of testing positive over two hypotheses. As well, let's use a confidence interval on $\beta_{BMI}$ to construct a confidence interval over the odds ratio:
```{r}
bmi_coeff <- coef(lmodr2)[[4]]
bmi_quartiles <- quantile(pima$bmi, na.rm=TRUE)
bmi_quartiles

third_quartile <- bmi_quartiles[[3]]
first_quartile <- bmi_quartiles[[1]]
odds_ratio <- exp(third_quartile * bmi_coeff) / exp(first_quartile * bmi_coeff)

# here's the ratio of the odds of testing positive
# with BMI at the third quartile vs the first quartile
odds_ratio

bmi_confint <- confint(lmodr2, "bmi")
lowerbound <- bmi_confint[[1]]
upperbound <- bmi_confint[[2]]

upperbound_odds_ratio <- exp(third_quartile * upperbound) / exp(first_quartile * upperbound)

lowerbound_odds_ratio <- exp(third_quartile * lowerbound) / exp(first_quartile * lowerbound)

# lowerbound of confidence interval
lowerbound_odds_ratio

# upperbound of confidence interval
upperbound_odds_ratio
```


## 2.h

Let's compute the means of diastolic conditional on $test$, and at the population level:
```{r}
# population level mean
m <- mean(pima$diastolic, na.rm = TRUE)
m

# mean conditional on test == 0
pima_test_negative <- pima[pima$test == 0,]
m_test_neg <- mean(pima_test_negative$diastolic, na.rm = TRUE)
m_test_neg

# mean conditional on test == 1
pima_test_positive <- pima[pima$test == 1,]
m_test_pos <- mean(pima_test_positive$diastolic, na.rm = TRUE)
m_test_pos
```


Now let's summarize the model:
```{r}
sumary(lmod2)
```

From comparing means in the dataset, we see that women who test positive do have higher diastolic blood pressure than those who test negative (and in fact, the population at large). However, the coefficient on $diastolic$ is not significant in this model, suggesting that $diastolic$ does not affect $test$.

This seems like a contradiction -- from simply comparing empirical means, we see that $test$ and $diastolic$ covary. However, significance is distinct from the sign and magnitude of the coefficient. The estimated coefficient on $diastolic$ tells us "what" is happening in the observed data, but the p-value tries to get at "why" we've observed it.

More precisely, the p-value tells us how likely the estimated coefficient would be under the null; we can detect an empirical correlation between $test$ and $diastolic$, but the p-value tells us the probability that such a coefficient would be generated by pure noise.
